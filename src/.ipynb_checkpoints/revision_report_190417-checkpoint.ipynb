{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import framenet as fn\n",
    "import dataio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### loading Korean FrameNet 1.1 data...\n",
      "\t# of instances in training data: 17838\n",
      "\t# of instances in dev data: 2548\n",
      "\t# of instances in test data: 5097\n"
     ]
    }
   ],
   "source": [
    "trn, dev, tst = dataio.load_framenet_data('1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfn = trn+dev+tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['태풍', 'Hugo가', '남긴', '피해들과', '회사', '내', '몇몇', '주요', '부서들의', '저조한', '실적들을', '반영하여,', 'Aetna', 'Life', 'and', 'Casualty', 'Co.의', '3분기', '순이익이', '182.6', '백만', '달러', '또는', '주당', '1.63', '달러로', '22', '%', '하락하였다.'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '이익.n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'Earnings_and_losses', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'I-Earner', 'B-Time', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(kfn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resource/info/FN17_frame2id.json','r') as f:\n",
    "    f2id = json.load(f)\n",
    "with open('../resource/info/fn1.7_frame2idx.json','r') as f:\n",
    "    frame2idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of fes: 1285\n",
      "# of frames: 1221\n"
     ]
    }
   ],
   "source": [
    "def gen_overall_fe2idx():\n",
    "    fes = []\n",
    "    for f in f2id:\n",
    "        fid = f2id[f]\n",
    "        for item in fn.frame(fid).FE:\n",
    "            fe = item\n",
    "            fe = fe.replace('-','_')\n",
    "            fes.append(fe)\n",
    "    fes = list(set(fes))\n",
    "    fes.sort()\n",
    "    fe2idx = {}\n",
    "    for fe in fes:\n",
    "        fe2idx[fe] = len(fe2idx)\n",
    "    \n",
    "    with open('../resource/info/fn1.7_fe2idx.json','w') as f:\n",
    "        json.dump(fe2idx, f, ensure_ascii=False, indent=4)\n",
    "    return fe2idx\n",
    "        \n",
    "fe2idx = gen_overall_fe2idx()\n",
    "print('# of fes:', len(fe2idx))\n",
    "\n",
    "def gen_overall_frargmap():\n",
    "    frargmap = {}\n",
    "    for f in f2id:\n",
    "        fid = f2id[f]\n",
    "        fidx = frame2idx[f]\n",
    "        fes = []\n",
    "        for item in fn.frame(fid).FE:\n",
    "            item = item.replace('-','_')\n",
    "            fe = fe2idx[item]\n",
    "            fes.append(fe)\n",
    "        fes = list(set(fes))\n",
    "        fes.sort()\n",
    "        \n",
    "        frargmap[fidx] = fes\n",
    "        \n",
    "    with open('../resource/info/fn1.7_frargmap.json', 'w') as f:\n",
    "        json.dump(frargmap, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    return frargmap\n",
    "        \n",
    "frargmap = gen_overall_frargmap()\n",
    "print('# of frames:', len(frargmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2frame = dict(zip(frame2idx.values(),frame2idx.keys()))\n",
    "idx2fe = dict(zip(fe2idx.values(),fe2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chemical-sense_description-Perceptual', 'Chemical-sense_description-Sensory']\n"
     ]
    }
   ],
   "source": [
    "def get_wrong_fe():\n",
    "    n = 0\n",
    "    errors = []\n",
    "    texts = {}\n",
    "    for item in kfn:\n",
    "        frames, args = item[2], item[3]\n",
    "        for f in frames:\n",
    "            if f != '_':\n",
    "                frame = f\n",
    "                frame_idx = frame2idx[frame]\n",
    "        text = []\n",
    "        fes = []\n",
    "        for idx in range(len(args)):\n",
    "            arg = args[idx]\n",
    "            t = item[0][idx]\n",
    "            if arg.startswith('B'):\n",
    "                fe = arg.split('-')[-1]\n",
    "                fes.append(fe)\n",
    "                if frame+'-'+fe in texts:\n",
    "                    text = texts[frame+'-'+fe]\n",
    "                    text.append(t)\n",
    "                    texts[frame+'-'+fe] = text\n",
    "                else:\n",
    "                    text = []\n",
    "                    text.append(t)\n",
    "                    texts[frame+'-'+fe] = text\n",
    "                    \n",
    "        frarg = frargmap[frame_idx]\n",
    "        frarg = [idx2fe[i] for i in frarg]\n",
    "        \n",
    "        for idx in range(len(fes)):\n",
    "            fe = fes[idx]\n",
    "            if fe not in fe2idx:\n",
    "                z = frame+'-'+fe\n",
    "                errors.append(z)\n",
    "                \n",
    "    errors = list(set(errors))\n",
    "        \n",
    "    with open('./error_190417.tsv','w') as f:\n",
    "        for error in errors:\n",
    "            text = ','.join(texts[error])\n",
    "            frame = error.split('-')[0]\n",
    "            fe = error.split('-')[1]\n",
    "            line = text+'\\t'+frame+'\\t'+fe+'\\n'\n",
    "            f.write(line)\n",
    "    return errors\n",
    "errors = get_wrong_fe()\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu: 자세.n\n",
      "플라톤 신학인지 뭔지가 들어오면서, 그런 성서가 만들어졌다고 생각합니다만, 이 소설의 도입은, 그런 말과는 달리 궁지에 몰린 소녀가 한 발로 선 자세로 시작됩니다.\n"
     ]
    }
   ],
   "source": [
    "def get_sent(input_word, input_frame, input_fe):\n",
    "    for item in kfn:\n",
    "        tokens, lus, frames, args = item[0], item[1], item[2], item[3]\n",
    "        text = ' '.join(tokens)\n",
    "        for idx in range(len(frames)):\n",
    "            f = frames[idx]\n",
    "            l = lus[idx]\n",
    "            if f != '_':\n",
    "                frame = f\n",
    "                lu = l\n",
    "        if input_frame == frame:\n",
    "\n",
    "            for idx in range(len(tokens)):\n",
    "                token = tokens[idx]\n",
    "                arg = args[idx]\n",
    "\n",
    "                if token == input_word and arg == 'B-'+input_fe:\n",
    "                    print('lu:', lu)\n",
    "                    print(text)\n",
    "\n",
    "\n",
    "input_word = '한'\n",
    "input_frame = 'Posture'\n",
    "input_fe = 'Supporting_body_part'\n",
    "get_sent(input_word, input_frame, input_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines2data(lines):\n",
    "    result = []\n",
    "    tsv = {}\n",
    "    sent = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('#'):\n",
    "            if 'text' in line:\n",
    "                tsv['second'] = line\n",
    "            else:\n",
    "                tsv['first'] = line\n",
    "        else:\n",
    "            if line != '':\n",
    "                token = line.split('\\t')\n",
    "                sent.append(token)\n",
    "            else:\n",
    "                tsv['conll'] = sent\n",
    "                result.append(tsv)\n",
    "                tsv = {}\n",
    "                sent = []\n",
    "    return result \n",
    "\n",
    "def load_ori_data(fname):\n",
    "    with open(fname,'r') as f:\n",
    "        input_data = f.readlines()\n",
    "    data = lines2data(input_data)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### loading Korean FrameNet 1.0 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n"
     ]
    }
   ],
   "source": [
    "a,b,c = dataio.load_framenet_data('1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_correction(fname):\n",
    "    with open('./fe_910416mapping_table_.csv','r') as f:\n",
    "        mt = f.readlines()\n",
    "    mapping_table = {}\n",
    "    for m in mt:\n",
    "        m = m.strip()\n",
    "        frame, ori_fe, new_fe = m.split(',')[0], m.split(',')[1], m.split(',')[2]\n",
    "        mt_tuple = (ori_fe, new_fe)\n",
    "        if frame not in mapping_table:\n",
    "            mt_list = []\n",
    "            mt_list.append(mt_tuple)\n",
    "            mapping_table[frame] = mt_list\n",
    "        else:\n",
    "            mt_list = mapping_table[frame]\n",
    "            mt_list.append(mt_tuple)\n",
    "            mapping_table[frame] = mt_list\n",
    "        \n",
    "    orifile = fname+'.bak'\n",
    "    \n",
    "    ori_data = load_ori_data(orifile)\n",
    "    \n",
    "    for item in ori_data:\n",
    "            \n",
    "        for tok in item['conll']:\n",
    "            if tok[3] != '_':\n",
    "                frame = tok[3]\n",
    "        change = False\n",
    "        if frame in mapping_table:\n",
    "            mt_tuples = mapping_table[frame]\n",
    "            for ori_fe, new_fe in mt_tuples:\n",
    "                \n",
    "\n",
    "                for tok in item['conll']:\n",
    "                    bio = 'B-'+ori_fe\n",
    "                    if tok[4] == bio:\n",
    "                        if new_fe != 'O':\n",
    "                            tok[4] = 'B-'+new_fe\n",
    "                        else:\n",
    "                            tok[4] = 'O'\n",
    "                        change = True\n",
    "                    bio = 'I-'+ori_fe\n",
    "                    if tok[4] == bio:\n",
    "                        if new_fe != 'O':\n",
    "                            tok[4] = 'I-'+new_fe\n",
    "                        else:\n",
    "                            tok[4] = 'O'\n",
    "                        change = True\n",
    "    with open(fname, 'w') as f:\n",
    "        for item in ori_data:\n",
    "            line1 = item['first']\n",
    "            line2 = item['second']\n",
    "            f.write(line1+'\\n')\n",
    "            f.write(line2+'\\n')\n",
    "            \n",
    "            for i in item['conll']:\n",
    "                line = '\\t'.join(i)\n",
    "                f.write(line+'\\n')\n",
    "            f.write('\\n')\n",
    "        \n",
    "files = ['../data/1.0/training.tsv', '../data/1.0/dev.tsv', '../data/1.0/test.tsv', '../data/1.1/training.tsv', '../data/1.1/dev.tsv', '../data/1.1/test.tsv']\n",
    "\n",
    "for fname in files:\n",
    "    error_correction(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
